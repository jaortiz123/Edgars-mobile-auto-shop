#!/usr/bin/env python3
"""
Edgar's Mobile Auto Shop â€” Sprint 1 local API server

Implements the S1 surface:
  - GET  /api/admin/appointments/board
  - PATCH /api/admin/appointments/<id>/move
  - GET  /api/appointments/<id>
  - PATCH /api/appointments/<id>
  - GET  /api/admin/dashboard/stats
  - GET  /api/admin/cars-on-premises
Plus health, simple auth stub, rate limits, and audit logging.

Notes
- DB: PostgreSQL (ENUM appointment_status) with lite tables from SCHEMA.md
- Status values are UPPERCASE in DB. We normalize inbound strings.
- Timestamps stored/fetched as UTC. Client converts to local.
- "Fallback to memory" is OFF by default; enable by env FALLBACK_TO_MEMORY=true.
"""
from __future__ import annotations

import logging, os, traceback, uuid, csv, io
from http import HTTPStatus
from flask import Flask, jsonify, request, Response
from flask_cors import CORS
from werkzeug.exceptions import HTTPException, NotFound, BadRequest, Forbidden, MethodNotAllowed
import time
import hmac
import json
import base64
from datetime import datetime, date, time as dtime, timezone, timedelta
from typing import Any, Dict, Optional, Tuple

from pythonjsonlogger import jsonlogger

import psycopg2
from psycopg2.extras import RealDictCursor
import sqlite3
import jwt
import os
import logging
import time
import json
import uuid
import traceback
import base64

# Redis for caching with graceful fallback
try:
    import redis
    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False

# ----------------------------------------------------------------------------
# App setup
# ----------------------------------------------------------------------------

class RequestIdFilter(logging.Filter):
    def filter(self, record):
        try:
            record.request_id = request.environ.get('REQUEST_ID', 'N/A')
        except RuntimeError:
            # No request context available (e.g., during server startup)
            record.request_id = 'N/A'
        return True

app = Flask(__name__)
CORS(app, supports_credentials=True, origins=['http://localhost:5173'])

app.config.setdefault("PROPAGATE_EXCEPTIONS", False)
app.config.setdefault("TRAP_HTTP_EXCEPTIONS", False)

REQUEST_ID_HEADER = "X-Request-Id"

def _req_id():
    rid = request.headers.get(REQUEST_ID_HEADER) or request.environ.get("REQUEST_ID")
    if not rid:
        rid = str(uuid.uuid4())
        request.environ["REQUEST_ID"] = rid
    return rid

def _ok(data, status=HTTPStatus.OK):
    return jsonify({"data": data, "errors": None, "meta": {"request_id": _req_id()}}), status

def _fail(status: int, code: str, detail: str, meta=None):
    return (
        jsonify({
            "data": None,
            "errors": [{"status": str(status), "code": code, "detail": detail}],
            "meta": {"request_id": _req_id(), **(meta or {})},
        }),
        status,
    )

logging.basicConfig(level=os.environ.get("LOG_LEVEL", "INFO"))
log = logging.getLogger("edgar.s1")
log.addFilter(RequestIdFilter())

JWT_SECRET = os.getenv("JWT_SECRET", "dev-secret-do-not-use-in-prod")
JWT_ALG = "HS256"

FALLBACK_TO_MEMORY = os.getenv("FALLBACK_TO_MEMORY", "false").lower() == "true"

# SQLite fallback database path
SQLITE_DB_PATH = os.getenv("SQLITE_DB_PATH", "/tmp/edgar_autoshop.db")

# Redis configuration with graceful fallback
_REDIS_CLIENT = None
if REDIS_AVAILABLE:
    try:
        _REDIS_CLIENT = redis.Redis(
            host=os.getenv("REDIS_HOST", "localhost"),
            port=int(os.getenv("REDIS_PORT", 6379)),
            db=int(os.getenv("REDIS_DB", 0)),
            password=os.getenv("REDIS_PASSWORD"),
            decode_responses=True,
            socket_timeout=1,
            socket_connect_timeout=1,
            health_check_interval=30
        )
        # Test connection
        _REDIS_CLIENT.ping()
        log.info("Redis connection established")
    except Exception as e:
        log.warning("Redis unavailable, continuing without cache: %s", e)
        _REDIS_CLIENT = None

# Simple in-memory rate limiter buckets {key: (count, window_start)}
_RATE: Dict[str, Tuple[int, float]] = {}
RATE_LIMIT_PER_MINUTE = int(os.getenv("MOVE_RATE_LIMIT_PER_MIN", "60"))

@app.before_request
def before_request():
    request.environ['REQUEST_ID'] = str(uuid.uuid4())

handler = logging.StreamHandler()
formatter = jsonlogger.JsonFormatter('%(asctime)s %(name)s %(levelname)s %(request_id)s %(message)s')
handler.setFormatter(formatter)
log.addHandler(handler)

# ----------------------------------------------------------------------------
# Helpers
# ----------------------------------------------------------------------------

def utcnow() -> datetime:
    return datetime.now(timezone.utc)


def init_sqlite_db(db_path: str):
    """Initialize SQLite database with schema and sample data"""
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row  # Enable dict-like access
    
    try:
        cursor = conn.cursor()
        
        # Create tables (SQLite version of PostgreSQL schema)
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS customers (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name VARCHAR(255) NOT NULL,
                phone VARCHAR(20),
                email VARCHAR(255),
                address TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS vehicles (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                customer_id INTEGER REFERENCES customers(id),
                make VARCHAR(100),
                model VARCHAR(100),
                year INTEGER,
                license_plate VARCHAR(20),
                notes TEXT
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS services (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name VARCHAR(255) NOT NULL,
                description TEXT,
                duration_minutes INTEGER,
                base_price DECIMAL(10,2)
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS appointments (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                customer_id INTEGER REFERENCES customers(id),
                vehicle_id INTEGER REFERENCES vehicles(id),
                service_id INTEGER REFERENCES services(id),
                status VARCHAR(50) DEFAULT 'SCHEDULED',
                start_ts TIMESTAMP,
                end_ts TIMESTAMP,
                total_amount DECIMAL(10,2) DEFAULT 0.00,
                paid_amount DECIMAL(10,2) DEFAULT 0.00,
                check_in_at TIMESTAMP,
                check_out_at TIMESTAMP,
                tech_id INTEGER,
                location_address TEXT,
                notes TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS appointment_services (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                appointment_id INTEGER REFERENCES appointments(id),
                name VARCHAR(255) NOT NULL,
                notes TEXT,
                estimated_hours DECIMAL(5,2),
                estimated_price DECIMAL(10,2),
                category VARCHAR(100)
            )
        ''')
        
        # Insert sample services
        cursor.execute('SELECT COUNT(*) FROM services')
        if cursor.fetchone()[0] == 0:
            services = [
                ('Oil Change', 'Standard oil change with filter', 30, 45.00),
                ('Brake Inspection', 'Complete brake system inspection', 45, 65.00),
                ('Battery Replacement', 'Replace car battery', 20, 120.00),
                ('Tire Rotation', 'Rotate and balance tires', 45, 50.00),
                ('Engine Diagnostics', 'Computer diagnostic scan', 60, 95.00),
                ('Transmission Service', 'Transmission fluid change', 90, 150.00)
            ]
            cursor.executemany(
                'INSERT INTO services (name, description, duration_minutes, base_price) VALUES (?, ?, ?, ?)',
                services
            )
        
        # Insert sample customers
        cursor.execute('SELECT COUNT(*) FROM customers')
        if cursor.fetchone()[0] == 0:
            customers = [
                ('John Smith', '(555) 123-4567', 'john.smith@email.com', '123 Main St, Sacramento, CA'),
                ('Maria Garcia', '(555) 234-5678', 'maria.garcia@email.com', '456 Oak Ave, Sacramento, CA'),
                ('David Johnson', '(555) 345-6789', 'david.johnson@email.com', '789 Pine St, Sacramento, CA'),
                ('Sarah Wilson', '(555) 456-7890', 'sarah.wilson@email.com', '321 Elm St, Sacramento, CA'),
                ('Michael Brown', '(555) 567-8901', 'michael.brown@email.com', '654 Maple Dr, Sacramento, CA')
            ]
            cursor.executemany(
                'INSERT INTO customers (name, phone, email, address) VALUES (?, ?, ?, ?)',
                customers
            )
        
        # Insert sample vehicles
        cursor.execute('SELECT COUNT(*) FROM vehicles')
        if cursor.fetchone()[0] == 0:
            vehicles = [
                (1, 'Toyota', 'Camry', 2020, 'ABC123', 'Regular maintenance customer'),
                (2, 'Honda', 'Civic', 2019, 'XYZ789', 'New customer'),
                (3, 'Ford', 'F-150', 2021, 'DEF456', 'Commercial vehicle'),
                (4, 'Nissan', 'Altima', 2018, 'GHI789', 'Frequent service visits'),
                (5, 'Chevrolet', 'Malibu', 2022, 'JKL012', 'Under warranty')
            ]
            cursor.executemany(
                'INSERT INTO vehicles (customer_id, make, model, year, license_plate, notes) VALUES (?, ?, ?, ?, ?, ?)',
                vehicles
            )
        
        # Insert sample appointments with various statuses and times
        cursor.execute('SELECT COUNT(*) FROM appointments')
        if cursor.fetchone()[0] == 0:
            from datetime import datetime, timedelta
            now = datetime.now()
            
            appointments = [
                # Today's appointments
                (1, 1, 1, 'SCHEDULED', (now + timedelta(hours=2)).isoformat(), 
                 (now + timedelta(hours=2, minutes=30)).isoformat(), 45.00, 0.00, None, None, None, 
                 '123 Main St, Sacramento, CA', 'Oil change scheduled for today'),
                
                (2, 2, 2, 'IN_PROGRESS', (now - timedelta(minutes=30)).isoformat(), 
                 (now + timedelta(minutes=15)).isoformat(), 65.00, 0.00, 
                 (now - timedelta(minutes=30)).isoformat(), None, None,
                 '456 Oak Ave, Sacramento, CA', 'Brake inspection in progress'),
                
                (3, 3, 3, 'READY', (now - timedelta(hours=1)).isoformat(), 
                 now.isoformat(), 120.00, 0.00, 
                 (now - timedelta(hours=1)).isoformat(), None, None,
                 '789 Pine St, Sacramento, CA', 'Battery replacement complete'),
                
                (4, 4, 4, 'COMPLETED', (now - timedelta(hours=3)).isoformat(), 
                 (now - timedelta(hours=2, minutes=15)).isoformat(), 50.00, 50.00,
                 (now - timedelta(hours=3)).isoformat(), (now - timedelta(hours=2)).isoformat(), None,
                 '321 Elm St, Sacramento, CA', 'Tire rotation completed'),
                
                # Tomorrow's appointments
                (5, 5, 5, 'SCHEDULED', (now + timedelta(days=1, hours=1)).isoformat(), 
                 (now + timedelta(days=1, hours=2)).isoformat(), 95.00, 0.00, None, None, None,
                 '654 Maple Dr, Sacramento, CA', 'Engine diagnostics scheduled'),
                
                (1, 1, 6, 'SCHEDULED', (now + timedelta(days=1, hours=3)).isoformat(), 
                 (now + timedelta(days=1, hours=4, minutes=30)).isoformat(), 150.00, 0.00, None, None, None,
                 '123 Main St, Sacramento, CA', 'Transmission service follow-up'),
                
                # This week's appointments
                (2, 2, 1, 'SCHEDULED', (now + timedelta(days=2, hours=2)).isoformat(), 
                 (now + timedelta(days=2, hours=2, minutes=30)).isoformat(), 45.00, 0.00, None, None, None,
                 '456 Oak Ave, Sacramento, CA', 'Regular oil change'),
                
                (3, 3, 2, 'SCHEDULED', (now + timedelta(days=3, hours=1)).isoformat(), 
                 (now + timedelta(days=3, hours=1, minutes=45)).isoformat(), 65.00, 0.00, None, None, None,
                 '789 Pine St, Sacramento, CA', 'Brake follow-up inspection'),
            ]
            
            cursor.executemany('''
                INSERT INTO appointments 
                (customer_id, vehicle_id, service_id, status, start_ts, end_ts, total_amount, paid_amount, 
                 check_in_at, check_out_at, tech_id, location_address, notes) 
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', appointments)
            
            # Add some appointment services
            appointment_services = [
                (1, 'Oil Change', 'Standard 5W-30 oil', 0.5, 45.00, 'Maintenance'),
                (2, 'Brake Inspection', 'Full brake system check', 0.75, 65.00, 'Safety'),
                (3, 'Battery Replacement', 'Group 24F battery', 0.33, 120.00, 'Electrical'),
                (4, 'Tire Rotation', 'All four tires rotated', 0.75, 50.00, 'Maintenance'),
                (5, 'Engine Diagnostics', 'OBD-II scan and analysis', 1.0, 95.00, 'Diagnostics'),
                (6, 'Transmission Service', 'ATF drain and fill', 1.5, 150.00, 'Maintenance'),
            ]
            
            cursor.executemany('''
                INSERT INTO appointment_services 
                (appointment_id, name, notes, estimated_hours, estimated_price, category) 
                VALUES (?, ?, ?, ?, ?, ?)
            ''', appointment_services)
        
        # Create indexes
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_customers_email ON customers(email)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_appointments_start_ts ON appointments(start_ts)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_appointments_status ON appointments(status)')
        
        conn.commit()
        log.info("SQLite database initialized with sample data at %s", db_path)
        
    except Exception as e:
        log.error("Failed to initialize SQLite database: %s", e)
        conn.rollback()
        raise
    finally:
        conn.close()


def utcnow() -> datetime:
    return datetime.now(timezone.utc)


class SqliteConnectionWrapper:
    """Wrapper to make SQLite connections work with existing PostgreSQL code"""
    def __init__(self, sqlite_conn):
        self._conn = sqlite_conn
        self._in_transaction = False
    
    def cursor(self, cursor_factory=None):
        return SqliteCursorWrapper(self._conn.cursor())
    
    def commit(self):
        self._conn.commit()
    
    def rollback(self):
        self._conn.rollback()
    
    def close(self):
        self._conn.close()
    
    def __enter__(self):
        self._in_transaction = True
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is None:
            self.commit()
        else:
            self.rollback()
        self._in_transaction = False


class SqliteCursorWrapper:
    """Wrapper to make SQLite cursors work with existing PostgreSQL code"""
    def __init__(self, sqlite_cursor):
        self._cursor = sqlite_cursor
    
    def execute(self, query, params=None):
        # Normalize some PostgreSQL-specific SQL to SQLite-compatible SQL when using the fallback DB.
        q = query
        try:
            # Replace positional %s placeholders with SQLite '?'
            q = q.replace('%s', '?')
            # Replace gen_random_uuid() and now() with SQLite-compatible expressions
            q = q.replace('gen_random_uuid()', "(lower(hex(randomblob(16))))")
            q = q.replace('now()', 'CURRENT_TIMESTAMP')
        except Exception:
            pass
        # Remove PostgreSQL cast shorthand '::text' and similar
        q = q.replace('::text', '')
        # Replace ILIKE with LIKE (SQLite is case-insensitive by default for ASCII)
        q = q.replace(' ILIKE ', ' LIKE ')
        # Some Postgres functions aren't available in SQLite; best-effort replacements
        q = q.replace('CONCAT_WS(', "(")
        # Execute with normalized query
        return self._cursor.execute(q, params or ())
    
    def fetchone(self):
        row = self._cursor.fetchone()
        return dict(row) if row else None
    
    def fetchall(self):
        rows = self._cursor.fetchall()
        return [dict(row) for row in rows] if rows else []
    
    def fetchmany(self, size=None):
        rows = self._cursor.fetchmany(size) if size else self._cursor.fetchmany()
        return [dict(row) for row in rows] if rows else []
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        pass


def db_conn():
    # Allow tests to monkeypatch backend.local_server.db_conn while the app may be imported as
    # the top-level module name. If a different module object exists under 'backend.local_server'
    # (e.g. tests patched that module), prefer calling that function to respect the patch.
    import sys
    alias_mod = sys.modules.get('backend.local_server')
    if alias_mod is not None and alias_mod is not sys.modules.get(__name__):
        alt = getattr(alias_mod, 'db_conn', None)
        if callable(alt):
            try:
                return alt()
            except Exception:
                # Fall back to local implementation on error
                pass

    cfg = dict(
        host=os.getenv("POSTGRES_HOST", "db"),
        port=int(os.getenv("POSTGRES_PORT", 5432)),
        dbname=os.getenv("POSTGRES_DB", "autoshop"),
        user=os.getenv("POSTGRES_USER", "user"),
        password=os.getenv("POSTGRES_PASSWORD", "password"),
        connect_timeout=int(os.getenv("POSTGRES_CONNECT_TIMEOUT", "2")),
    )
    try:
        conn = psycopg2.connect(cursor_factory=RealDictCursor, **cfg)
        return conn
    except Exception as e:
        log.error("DB connect failed: %s", e)
        if FALLBACK_TO_MEMORY:
            # Initialize SQLite database if it doesn't exist
            if not os.path.exists(SQLITE_DB_PATH):
                log.info("Initializing SQLite fallback database...")
                init_sqlite_db(SQLITE_DB_PATH)
            
            # Return wrapped SQLite connection
            sqlite_conn = sqlite3.connect(SQLITE_DB_PATH)
            sqlite_conn.row_factory = sqlite3.Row  # Enable dict-like access
            wrapped_conn = SqliteConnectionWrapper(sqlite_conn)
            log.info("Using SQLite fallback database at %s", SQLITE_DB_PATH)
            return wrapped_conn
        raise RuntimeError("DB connection failed")


def redis_get(key: str) -> Optional[str]:
    """Get value from Redis with graceful fallback"""
    if not _REDIS_CLIENT:
        return None
    try:
        return _REDIS_CLIENT.get(key)
    except Exception as e:
        log.warning("Redis get failed for key %s: %s", key, e)
        return None


def redis_set(key: str, value: str, ex: int = None) -> bool:
    """Set value in Redis with graceful fallback"""
    if not _REDIS_CLIENT:
        return False
    try:
        _REDIS_CLIENT.set(key, value, ex=ex)
        return True
    except Exception as e:
        log.warning("Redis set failed for key %s: %s", key, e)
        return False


def format_duration_hours(hours: float) -> str:
    """Format duration in hours to human-readable string"""
    if hours is None or hours < 0:
        return "N/A"
    
    if hours < 1:
        minutes = int(hours * 60)
        return f"{minutes}m"
    elif hours < 24:
        return f"{hours:.1f}h"
    else:
        days = int(hours // 24)
        remaining_hours = hours % 24
        if remaining_hours < 1:
            return f"{days}d"
        else:
            return f"{days}d {remaining_hours:.1f}h"


_STATUS_ALIASES = {
    "scheduled": "SCHEDULED",
    "in_progress": "IN_PROGRESS",
    "in-progress": "IN_PROGRESS",
    "ready": "READY",
    "completed": "COMPLETED",
    "no_show": "NO_SHOW",
    "no-show": "NO_SHOW",
    "canceled": "CANCELED",
}

ALLOWED_TRANSITIONS = {
    "SCHEDULED": {"IN_PROGRESS", "READY", "NO_SHOW"},
    "IN_PROGRESS": {"READY", "COMPLETED"},
    "READY": {"COMPLETED"},
    "COMPLETED": set(),
    "NO_SHOW": set(),
    "CANCELED": set(),
}


def norm_status(s: str) -> str:
    if not s:
        raise BadRequest("Status required")
    s2 = s.strip()
    s2 = _STATUS_ALIASES.get(s2, s2).upper()
    return s2


def require_auth_role(required: Optional[str] = None) -> Dict[str, Any]:
    """Very light JWT check. Expected header: Authorization: Bearer <token>.
    Payload example: {"sub":"user-1","role":"Owner"}
    """
    auth = request.headers.get("Authorization", "")
    if not auth.startswith("Bearer "):
        raise Forbidden("Missing token")
    token = auth.split(" ", 1)[1]
    try:
        payload = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALG])
    except Exception:
        raise Forbidden("Invalid token")
    role = payload.get("role", "Advisor")
    if required and role != required:
        # Owner can do anything
        if role != "Owner":
            raise Forbidden("Forbidden")
    return payload


def rate_limit(key: str, max_calls: Optional[int] = None, window_seconds: Optional[int] = None):
    """Simple rate limiter.

    Backwards compatible: existing callers use rate_limit(key).
    New callers may pass max_calls and window_seconds (e.g., rate_limit(key, 5, 3600)).
    """
    if max_calls is None:
        max_calls = RATE_LIMIT_PER_MINUTE
    if window_seconds is None:
        window_seconds = 60

    now = time.time()
    count, start = _RATE.get(key, (0, now))
    if now - start >= float(window_seconds):
        _RATE[key] = (1, now)
        return
    if count + 1 > int(max_calls):
        raise Forbidden("Rate limit exceeded")
    _RATE[key] = (count + 1, start)


def audit(conn, user_id: str, action: str, entity: str, entity_id: str, before: Dict, after: Dict):
    try:
        with conn.cursor() as cur:
            cur.execute(
                """
                INSERT INTO audit_logs (id, user_id, action, entity, entity_id, before, after, created_at)
                VALUES (gen_random_uuid(), %s, %s, %s, %s, %s::jsonb, %s::jsonb, now())
                """,
                (user_id, action, entity, entity_id, json.dumps(before), json.dumps(after)),
            )
    except Exception as e:
        log.warning("audit insert failed: %s", e)

# Backwards-compatible wrapper expected by tests
def audit_log(*args, **kwargs):
    """Compatibility wrapper with two supported signatures:
    - audit_log(conn, user_id, action, entity, entity_id, before, after)
    - audit_log(user_id, action, details)
    Tests patch `audit_log` and expect the simple (user_id, action, details) signature.
    """
    # If caller passed a DB connection as first arg, forward to audit()
    if args and hasattr(args[0], 'cursor'):
        return audit(*args, **kwargs)

    # Simple signature: (user_id, action, details)
    user_id = args[0] if len(args) > 0 else kwargs.get('user_id')
    action = args[1] if len(args) > 1 else kwargs.get('action')
    details = args[2] if len(args) > 2 else kwargs.get('details', {})

    # For simple calls (user_id, action, details) avoid opening DB connections
    # Tests expect audit_log to be called but not necessarily write to DB.
    try:
        log.info("audit_log: user=%s action=%s details=%s", user_id, action, details)
        return
    except Exception as e:
        log.warning("audit_log simple failed: %s", e)

# ----------------------------------------------------------------------------
# Error Handler
# ----------------------------------------------------------------------------

def handle_http_exception(e: HTTPException):
    # Don't treat these as 500s.
    status = e.code or 500
    # Optional: map to stable codes
    code_map = {
        400: "BAD_REQUEST",
        401: "UNAUTHORIZED",
        403: "FORBIDDEN",
        404: "NOT_FOUND",
        405: "METHOD_NOT_ALLOWED",
        429: "RATE_LIMITED",
    }
    code = code_map.get(status, "HTTP_ERROR")
    # Log at WARNING, not ERROR
    logging.getLogger("edgar.s1").warning(
        "http_exception",
        extra={"request_id": _req_id(), "status": status, "path": request.path, "method": request.method, "error": str(e)},
    )
    # e.description is user-facing but safe
    return _fail(status, code, e.description or e.name or "HTTP error")

def handle_unexpected_exception(e: Exception):
    log = logging.getLogger("edgar.s1")
    log.error(
        "unhandled_exception",
        extra={"request_id": _req_id(), "path": request.path, "method": request.method},
    )
    log.error("traceback:\n%s", traceback.format_exc())
    return _fail(HTTPStatus.INTERNAL_SERVER_ERROR, "INTERNAL", "Internal server error")

app.register_error_handler(HTTPException, handle_http_exception)
app.register_error_handler(Exception, handle_unexpected_exception)
# Optional explicit mappings (not strictly required, but fine):
app.register_error_handler(NotFound, handle_http_exception)
app.register_error_handler(BadRequest, handle_http_exception)
app.register_error_handler(MethodNotAllowed, handle_http_exception)
app.register_error_handler(Forbidden, handle_http_exception)


# ----------------------------------------------------------------------------
# Health
# ----------------------------------------------------------------------------
@app.route("/health", methods=["GET"])
def health():
    try:
        conn = db_conn()
        if conn:
            with conn.cursor() as cur:
                cur.execute("SELECT 1")
            conn.close()
            return jsonify({"status": "ok", "db": "up"})
        else:
            return jsonify({"status": "ok", "db": "memory"})
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500

# ----------------------------------------------------------------------------
# Board
# ----------------------------------------------------------------------------
@app.route("/api/admin/appointments/board", methods=["GET"])
def get_board():
    # optional auth in S1 â€” require a token but no strict role
    try:
        require_auth_role()  # raise if missing/invalid
    except Exception:
        pass

    frm = request.args.get("from")
    to = request.args.get("to")
    tech_id = request.args.get("techId")

    conn = db_conn()
    if conn is None:
        # Minimal memory board (unspecified data) â€” keep empty in S1 if no DB
        return jsonify({"columns": _empty_columns(), "cards": []})

    where = ["1=1"]
    params: list[Any] = []
    if frm:
        where.append("a.start_ts >= ?")
        params.append(frm)
    if to:
        where.append("a.end_ts <= ?")
        params.append(to)
    if tech_id:
        where.append("a.tech_id = ?")
        params.append(tech_id)

    where_sql = " AND ".join(where)

    with conn:
        with conn.cursor() as cur:
            # Check if we're using SQLite (simplified query)
            is_sqlite = type(conn).__name__ == 'SqliteConnectionWrapper'
            
            if is_sqlite:
                # Simplified SQLite-compatible query with COALESCE defaults for customer and vehicle
                cur.execute(
                    f"""
                    SELECT CAST(a.id AS TEXT) as id,
                           CAST(a.status AS TEXT) as status,
                           a.start_ts AS start_ts,
                           a.end_ts AS end_ts,
                           COALESCE(a.total_amount, 0) AS price,
                           COALESCE(c.name, 'Unknown Customer') AS customer_name,
                           COALESCE(
                             (TRIM(COALESCE(CAST(v.year AS TEXT), '') || ' ' || COALESCE(v.make, '') || ' ' || COALESCE(v.model, ''))),
                             'Unknown Vehicle'
                           ) AS vehicle_label,
                           SUBSTR(
                               (SELECT GROUP_CONCAT(sv.name, ', ')
                                FROM appointment_services sv WHERE sv.appointment_id = a.id),
                               1, 120
                           ) AS services_summary,
                           ROW_NUMBER() OVER(PARTITION BY a.status ORDER BY a.start_ts) AS position
                    FROM appointments a
                    LEFT JOIN customers c ON c.id = a.customer_id
                    LEFT JOIN vehicles v ON v.id = a.vehicle_id
                    WHERE {where_sql}
                    ORDER BY a.status, a.start_ts
                    """,
                    params,
                )
            else:
                # Original PostgreSQL query with COALESCE defaults for customer and vehicle
                cur.execute(
                    f"""
                    SELECT a.id::text,
                           a.status::text,
                           a.start_ts AS start_ts,
                           a.end_ts AS end_ts,
                            COALESCE(a.total_amount, 0) AS price,
                            COALESCE(c.name, 'Unknown Customer') AS customer_name,
                            COALESCE(CONCAT_WS(' ', v.year::text, v.make, v.model), 'Unknown Vehicle') AS vehicle_label,
                            SUBSTRING((SELECT STRING_AGG(sv.name, ', ')
                                      FROM appointment_services sv WHERE sv.appointment_id = a.id)::text FROM 1 FOR 120) AS services_summary,
                           ROW_NUMBER() OVER(PARTITION BY a.status ORDER BY a.start_ts) AS position
                    FROM appointments a
                    LEFT JOIN customers c ON c.id = a.customer_id
                    LEFT JOIN vehicles v  ON v.id = a.vehicle_id
                    WHERE {where_sql}
                    ORDER BY a.status, a.start_ts
                    """,
                    params,
                )
            
            rows = cur.fetchall()

            cards = []
            for r in rows:
                # Handle date parsing for SQLite (strings) vs PostgreSQL (datetime objects)
                start_ts = r["start_ts"]
                end_ts = r.get("end_ts")
                
                if start_ts:
                    if isinstance(start_ts, str):
                        # SQLite returns ISO strings, parse them
                        from datetime import datetime
                        start_dt = datetime.fromisoformat(start_ts.replace('Z', '+00:00'))
                        start_iso = start_dt.astimezone(timezone.utc).isoformat()
                    else:
                        # PostgreSQL returns datetime objects
                        start_iso = start_ts.astimezone(timezone.utc).isoformat()
                else:
                    start_iso = None
                
                if end_ts:
                    if isinstance(end_ts, str):
                        # SQLite returns ISO strings, parse them
                        from datetime import datetime
                        end_dt = datetime.fromisoformat(end_ts.replace('Z', '+00:00'))
                        end_iso = end_dt.astimezone(timezone.utc).isoformat()
                    else:
                        # PostgreSQL returns datetime objects
                        end_iso = end_ts.astimezone(timezone.utc).isoformat()
                else:
                    end_iso = None
                
                # Defensive Python-level fallbacks in case DB returns NULL/empty strings
                cust = r.get("customer_name") or None
                veh = r.get("vehicle_label") or None

                cards.append(
                    {
                        "id": r["id"],
                        "status": r["status"],
                        "position": int(r["position"]),
                        "start": start_iso,
                        "end": end_iso,
                        "customerName": cust if cust and str(cust).strip() else "Unknown Customer",
                        "vehicle": veh if veh and str(veh).strip() else "Unknown Vehicle",
                        "servicesSummary": r.get("services_summary") or None,
                        "price": float(r.get("price") or 0),
                        "tags": [],
                    }
                )

            # Enrich cards with time-aware context
            for c in cards:
                try:
                    time_ctx = calculate_time_context(c)
                    c.update(time_ctx)
                except Exception:
                    pass

            # Sort cards within each column by priority: overdue first, then soonest, then original position
            def sort_priority(card):
                if card.get('isOverdue'):
                    # sort most overdue first (larger minutesLate -> higher urgency)
                    return (0, -int(card.get('minutesLate', 0)))
                if card.get('timeUntilStart') is not None:
                    return (1, int(card.get('timeUntilStart')))
                return (2, int(card.get('position', 999)))

            # Recompute positions per column
            for key, title in _ordered_columns():
                column_cards = [c for c in cards if c.get('status') == key]
                column_cards.sort(key=sort_priority)
                for i, card in enumerate(column_cards):
                    card['position'] = i

            # Column aggregates
            if is_sqlite:
                cur.execute(
                    f"""
                    SELECT CAST(a.status AS TEXT) AS key,
                           COUNT(*) AS count,
                           COALESCE(SUM(a.total_amount), 0) AS sum
                    FROM appointments a
                    WHERE {where_sql}
                    GROUP BY a.status
                    """,
                    params,
                )
            else:
                cur.execute(
                    f"""
                    SELECT a.status::text AS key,
                           COUNT(*) AS count,
                           COALESCE(SUM(a.total_amount), 0) AS sum
                    FROM appointments a
                    WHERE {where_sql}
                    GROUP BY a.status
                    """,
                    params,
                )
            agg = {r["key"]: (int(r["count"]), float(r["sum"])) for r in cur.fetchall()}

    conn.close()
    columns = []
    for key, title in _ordered_columns():
        c = agg.get(key, (0, 0.0))
        columns.append({"key": key, "title": title, "count": c[0], "sum": round(c[1], 2)})

    return jsonify({"columns": columns, "cards": cards})


def _empty_columns():
    return [
        {"key": key, "title": title, "count": 0, "sum": 0.0}
        for key, title in _ordered_columns()
    ]


def _ordered_columns():
    return [
        ("SCHEDULED", "Scheduled"),
        ("IN_PROGRESS", "In Progress"),
        ("READY", "Ready"),
        ("COMPLETED", "Completed"),
        ("NO_SHOW", "No-Show"),
    ]

def calculate_time_context(card: dict, current_time: Optional[datetime] = None) -> dict:
    """Calculate time-aware context for a card dict (expects UTC ISO strings in card['start'])."""
    if current_time is None:
        current_time = utcnow()

    out = {}
    start_iso = card.get('start')
    if start_iso:
        try:
            scheduled_dt = datetime.fromisoformat(start_iso.replace('Z', '+00:00'))
        except Exception:
            try:
                scheduled_dt = datetime.fromisoformat(start_iso)
            except Exception:
                scheduled_dt = None
        if scheduled_dt:
            # Ensure scheduled_dt is timezone-aware (UTC)
            if scheduled_dt.tzinfo is None:
                scheduled_dt = scheduled_dt.replace(tzinfo=timezone.utc)
            scheduled_dt = scheduled_dt.astimezone(timezone.utc)
            out['scheduledTime'] = scheduled_dt.strftime('%I:%M %p')
            out['appointmentDate'] = scheduled_dt.date().isoformat()

            time_diff = (scheduled_dt - current_time).total_seconds() / 60.0
            if time_diff > 0:
                out['timeUntilStart'] = int(time_diff)
            else:
                # If appointment is more than 15 minutes late, mark overdue
                if time_diff < -15:
                    out['isOverdue'] = True
                    out['minutesLate'] = int(abs(time_diff))
                else:
                    out['timeUntilStart'] = int(time_diff)

    # If appointment is in progress, compute elapsed and compare to expected duration
    if card.get('status') == 'IN_PROGRESS' and card.get('start'):
        try:
            start_dt = datetime.fromisoformat(card['start'].replace('Z', '+00:00'))
            start_dt = start_dt.astimezone(timezone.utc)
            elapsed_minutes = (current_time - start_dt).total_seconds() / 60.0
            expected_duration = int(card.get('estimatedDuration') or 120)
            if elapsed_minutes > expected_duration:
                out['isOverdue'] = True
                out['minutesLate'] = int(elapsed_minutes - expected_duration)
        except Exception:
            pass

    # Ensure numeric fields are integers where appropriate
    if 'minutesLate' in out:
        out['minutesLate'] = int(out['minutesLate'])
    if 'timeUntilStart' in out:
        out['timeUntilStart'] = int(out['timeUntilStart'])

    return out

# ----------------------------------------------------------------------------
# Move endpoint
# ----------------------------------------------------------------------------
@app.route("/api/admin/appointments/<appt_id>/move", methods=["PATCH"])
def move_card(appt_id: str):
    user = None
    try:
        user = require_auth_role()  # require any authenticated user
    except Exception:
        pass

    # rate limit (by IP or user id)
    key = f"move:{request.remote_addr}:{user.get('sub') if user else 'anon'}"
    try:
        rate_limit(key)
    except Forbidden:
        return _fail(429, 'RATE_LIMITED', 'Rate limit exceeded')

    body = request.get_json(force=True, silent=False) or {}
    new_status = norm_status(str(body.get("status", "")))
    position = int(body.get("position", 1))

    conn = db_conn()
    if conn is None:
        # memory noop
        return jsonify({"id": appt_id, "status": new_status, "position": position})

    with conn:
        with conn.cursor() as cur:
            cur.execute("SELECT id::text, status::text, total_amount FROM appointments WHERE id = %s", (appt_id,))
            row = cur.fetchone()
            if not row:
                return _fail(404, 'RESOURCE_NOT_FOUND', 'Appointment not found')
            old_status = row["status"]
            if new_status not in ALLOWED_TRANSITIONS.get(old_status, set()):
                return _fail(400, 'INVALID_TRANSITION', f"Invalid transition {old_status} â†’ {new_status}")

            cur.execute(
                "UPDATE appointments SET status = %s WHERE id = %s RETURNING id",
                (new_status, appt_id),
            )
            audit(conn, (user or {}).get("sub", "anon"), "STATUS_CHANGE", "appointment", appt_id, {"status": old_status}, {"status": new_status})

    conn.close()
    return _ok({"id": appt_id, "status": new_status, "position": position})
# ----------------------------------------------------------------------------
# Drawer
# ----------------------------------------------------------------------------
@app.route("/api/appointments/<appt_id>", methods=["GET", "PATCH"])
def appointment_handler(appt_id: str):
    if request.method == "GET":
        return get_appointment(appt_id)
    elif request.method == "PATCH":
        return patch_appointment(appt_id)

def get_appointment(appt_id: str):
    conn = db_conn()
    if conn is None:
        return jsonify({"error": "DB unavailable"}), 503

    # Detect if we're using SQLite fallback and adjust query syntax
    is_sqlite = type(conn).__name__ == 'SqliteConnectionWrapper'

    with conn:
        with conn.cursor() as cur:
            if is_sqlite:
                # SQLite-compatible query
                cur.execute(
                    """
                    SELECT CAST(a.id AS TEXT) as id, 
                           CAST(a.status AS TEXT) as status, 
                           a.start_ts, a.end_ts, a.total_amount, a.paid_amount,
                           a.check_in_at, a.check_out_at, 
                           CAST(a.tech_id AS TEXT) as tech_id,
                           CAST(c.id AS TEXT) as customer_id, c.name as customer_name, c.email, c.phone,
                           CAST(v.id AS TEXT) as vehicle_id, v.year, v.make, v.model, v.license_plate as vin
                    FROM appointments a
                    LEFT JOIN customers c ON c.id = a.customer_id
                    LEFT JOIN vehicles  v ON v.id = a.vehicle_id
                    WHERE a.id = ?
                    """,
                    (appt_id,),
                )
            else:
                # PostgreSQL query
                cur.execute(
                    """
                    SELECT a.id::text, a.status::text, a.start_ts, a.end_ts, a.total_amount, a.paid_amount,
                           a.check_in_at, a.check_out_at, a.tech_id::text,
                           c.id::text as customer_id, c.name as customer_name, c.email, c.phone,
                           v.id::text as vehicle_id, v.year, v.make, v.model, v.vin
                    FROM appointments a
                    LEFT JOIN customers c ON c.id = a.customer_id
                    LEFT JOIN vehicles  v ON v.id = a.vehicle_id
                    WHERE a.id = %s
                    """,
                    (appt_id,),
                )
            
            a = cur.fetchone()
            if not a:
                return jsonify({"error": "Not found"}), 404

            if is_sqlite:
                # SQLite query for services
                cur.execute(
                    """
                    SELECT CAST(id AS TEXT) as id, 
                           CAST(appointment_id AS TEXT) as appointment_id, 
                           name, notes, estimated_hours, estimated_price 
                    FROM appointment_services 
                    WHERE appointment_id = ? 
                    ORDER BY id
                    """, 
                    (appt_id,)
                )
            else:
                # PostgreSQL query for services
                cur.execute("SELECT id::text, appointment_id::text, name, notes, estimated_hours, estimated_price FROM appointment_services WHERE appointment_id = %s ORDER BY created_at", (appt_id,))
            services = cur.fetchall()

    conn.close()

    def iso(dt):
        if dt is None:
            return None
        # Handle SQLite string timestamps vs PostgreSQL datetime objects
        if isinstance(dt, str):
            # SQLite returns ISO strings, parse and convert to UTC
            try:
                dt_obj = datetime.fromisoformat(dt.replace('Z', '+00:00'))
                return dt_obj.astimezone(timezone.utc).isoformat()
            except:
                return dt  # Return as-is if parsing fails
        else:
            # PostgreSQL datetime object
            return dt.astimezone(timezone.utc).isoformat() if dt else None

    appointment = {
        "id": a["id"],
        "status": a["status"],
        "start": iso(a.get("start_ts")),
        "end": iso(a.get("end_ts")),
        "total_amount": float(a.get("total_amount") or 0),
        "paid_amount": float(a.get("paid_amount") or 0),
        "check_in_at": iso(a.get("check_in_at")),
        "check_out_at": iso(a.get("check_out_at")),
        "tech_id": a.get("tech_id"),
    }
    customer = {
        "id": a.get("customer_id"),
        "name": a.get("customer_name"),
        "email": a.get("email"),
        "phone": a.get("phone"),
    }
    vehicle = {
        "id": a.get("vehicle_id"),
        "year": a.get("year"),
        "make": a.get("make"),
        "model": a.get("model"),
        "vin": a.get("vin"),
    }
    svc_list = [
        {
            "id": s["id"],
            "appointment_id": s["appointment_id"],
            "name": s["name"],
            "notes": s.get("notes"),
            "estimated_hours": float(s["estimated_hours"]) if s.get("estimated_hours") is not None else None,
            "estimated_price": float(s["estimated_price"]) if s.get("estimated_price") is not None else None,
        }
        for s in services
    ]

    return jsonify({"appointment": appointment, "customer": customer, "vehicle": vehicle, "services": svc_list})


def patch_appointment(appt_id: str):
    body = request.get_json(force=True, silent=False) or {}
    # Normalize status if provided
    if "status" in body:
        body["status"] = norm_status(str(body["status"]))

    fields = [
        ("status", "status"),
        ("start", "start_ts"),
        ("end", "end_ts"),
        ("total_amount", "total_amount"),
        ("paid_amount", "paid_amount"),
        ("check_in_at", "check_in_at"),
        ("check_out_at", "check_out_at"),
        ("tech_id", "tech_id"),
    ]
    sets = []
    params: list[Any] = []
    for key, col in fields:
        if key in body and body[key] is not None:
            sets.append(f"{col} = %s")
            params.append(body[key])
    if not sets:
        raise BadRequest("No valid fields to update")

    conn = db_conn()
    if conn is None:
        return jsonify({"ok": True})

    # Detect if we're using SQLite fallback
    is_sqlite = type(conn).__name__ == 'SqliteConnectionWrapper'

    with conn:
        with conn.cursor() as cur:
            if is_sqlite:
                # SQLite-compatible queries - replace %s with ? and remove ::text casting
                sets_sqlite = [s.replace('%s', '?') for s in sets]
                cur.execute(f"SELECT CAST(id AS TEXT) as id, CAST(status AS TEXT) as status FROM appointments WHERE id = ?", (appt_id,))
                old = cur.fetchone()
                if not old:
                    return jsonify({"error": "Not found"}), 404
                cur.execute(f"UPDATE appointments SET {', '.join(sets_sqlite)} WHERE id = ?", (*params, appt_id))
            else:
                # PostgreSQL queries
                cur.execute("SELECT id::text, status::text FROM appointments WHERE id = %s", (appt_id,))
                old = cur.fetchone()
                if not old:
                    return jsonify({"error": "Not found"}), 404
                cur.execute(f"UPDATE appointments SET {', '.join(sets)} WHERE id = %s RETURNING id", (*params, appt_id))
            
            user_id = "system"
            audit(conn, user_id, "APPT_PATCH", "appointment", appt_id, {"status": old["status"]}, {k: body[k] for k in body.keys()})

    conn.close()
    return jsonify({"ok": True})





@app.route("/api/admin/appointments", methods=["GET"])
def get_admin_appointments():
    """Returns a paginated list of appointments with filtering."""
    args = request.args
    # Pagination parameters
    limit = int(args.get("limit", 50))
    # Clamp limit between 1 and 200
    if limit < 1 or limit > 200:
        raise BadRequest("limit must be between 1 and 200")
    offset = int(args.get("offset", 0))
    if offset < 0:
        raise BadRequest("offset must be non-negative")
    cursor = args.get("cursor")

    # Validate that cursor and offset are not used together
    if cursor and offset > 0:
        raise BadRequest("cannot use both cursor and offset parameters together")

    # Use canonical start_ts and end_ts columns directly
    co_start = "a.start_ts"

    # Filtering
    where = ["1=1"]
    params = []
    if args.get("status"):
        where.append("a.status = %s")
        params.append(norm_status(args["status"]))
    if args.get("from"):
        # Validate date format
        try:
            # Try to parse various ISO formats
            from_date = args["from"]
            if from_date:
                # Handle URL encoding issues: space back to +, then handle 'Z' suffix
                fixed_date = from_date.replace(' ', '+')
                normalized_date = fixed_date.replace('Z', '+00:00') if fixed_date.endswith('Z') else fixed_date
                datetime.fromisoformat(normalized_date)
        except ValueError:
            raise BadRequest("Invalid 'from' date format. Expected ISO format (e.g., '2023-12-01T10:00:00Z')")
        where.append("a.start_ts >= %s")
        params.append(args["from"])
    if args.get("to"):
        # Validate date format
        try:
            # Try to parse various ISO formats
            to_date = args["to"]
            if to_date:
                # Handle URL encoding issues: space back to +, then handle 'Z' suffix
                fixed_date = to_date.replace(' ', '+')
                normalized_date = fixed_date.replace('Z', '+00:00') if fixed_date.endswith('Z') else fixed_date
                datetime.fromisoformat(normalized_date)
        except ValueError:
            raise BadRequest("Invalid 'to' date format. Expected ISO format (e.g., '2023-12-01T18:00:00Z')")
        where.append("a.end_ts <= %s")
        params.append(args["to"])
    # Filter by technician ID if provided
    if args.get("techId"):
        where.append("a.tech_id = %s")
        params.append(args.get("techId"))
    # Simple text search on customer and vehicle fields
    if args.get("q"):
        q = f"%{args.get('q')}%"
        where.append(
            "(c.name ILIKE %s OR v.make ILIKE %s OR v.model ILIKE %s OR c.email ILIKE %s OR c.phone ILIKE %s)"
        )
        params.extend([q, q, q, q, q])

    where_sql = " AND ".join(where)

    conn = db_conn()
    # If DB is unavailable, return empty list (S1 memory fallback behavior)
    if conn is None:
        return jsonify({"appointments": [], "nextCursor": None})
    
    # Detect if we're using SQLite fallback and adjust query syntax
    is_sqlite = type(conn).__name__ == 'SqliteConnectionWrapper'
    
    if is_sqlite:
        # SQLite-compatible query
        where_sql = where_sql.replace('ILIKE', 'LIKE')  # SQLite uses LIKE instead of ILIKE
        query = f"""
             SELECT CAST(a.id AS TEXT) as id,
                     a.status,
                     a.start_ts AS start_ts,
                     a.end_ts AS end_ts,
                     COALESCE(a.total_amount, 0) AS total_amount,
                     c.name as customer_name,
                     COALESCE(v.make, '') || ' ' || COALESCE(v.model, '') as vehicle_label
             FROM appointments a
             LEFT JOIN customers c ON c.id = a.customer_id
             LEFT JOIN vehicles v ON v.id = a.vehicle_id
             WHERE {where_sql}
             ORDER BY a.start_ts ASC, a.id ASC
             LIMIT ? OFFSET ?
         """
    else:
        # PostgreSQL query
        query = f"""
             SELECT a.id::text,
                     a.status::text,
                     a.start_ts AS start_ts,
                     a.end_ts AS end_ts,
                     COALESCE(a.total_amount, 0) AS total_amount,
                     c.name as customer_name,
                     COALESCE(v.make, '') || ' ' || COALESCE(v.model, '') as vehicle_label
             FROM appointments a
             LEFT JOIN customers c ON c.id = a.customer_id
             LEFT JOIN vehicles v ON v.id = a.vehicle_id
             WHERE {where_sql}
             ORDER BY a.start_ts ASC, a.id ASC
             LIMIT %s OFFSET %s
         """

    with conn:
        with conn.cursor() as cur:
            if is_sqlite:
                # SQLite uses ? placeholders
                cur.execute(query, (*params, limit, offset))
            else:
                # PostgreSQL uses %s placeholders
                cur.execute(query, (*params, limit, offset))
            appointments = cur.fetchall()
    
    # Compute position for each appointment
    for idx, appt in enumerate(appointments):
        # position in the full result set
        appt['position'] = offset + idx + 1

    # Close DB connection if it has a `close` method
    try:
        conn.close()
    except AttributeError:
        pass

    next_cursor = None
    if len(appointments) == limit and appointments and appointments[-1].get('start_ts'):
        last_appt = appointments[-1]
        if is_sqlite:
            # For SQLite, start_ts might be a string
            start_ts_str = last_appt['start_ts']
            if isinstance(start_ts_str, str):
                dt = datetime.fromisoformat(start_ts_str.replace('Z', '+00:00'))
                cursor_data = f"{dt.isoformat()},{last_appt['id']}"
            else:
                cursor_data = f"{start_ts_str.isoformat()},{last_appt['id']}"
        else:
            # PostgreSQL datetime object
            cursor_data = f"{last_appt['start_ts'].isoformat()},{last_appt['id']}"
        next_cursor = base64.b64encode(cursor_data.encode('utf-8')).decode('utf-8')

    # Serialize appointment fields for JSON
    for appt in appointments:
        # Convert datetime to ISO strings
        if appt.get('start_ts'):
            if is_sqlite and isinstance(appt['start_ts'], str):
                # SQLite returns strings, convert to proper ISO format
                dt = datetime.fromisoformat(appt['start_ts'].replace('Z', '+00:00'))
                appt['start_ts'] = dt.astimezone(timezone.utc).isoformat()
            else:
                # PostgreSQL datetime object
                appt['start_ts'] = appt['start_ts'].astimezone(timezone.utc).isoformat()
        if appt.get('end_ts'):
            if is_sqlite and isinstance(appt['end_ts'], str):
                dt = datetime.fromisoformat(appt['end_ts'].replace('Z', '+00:00'))
                appt['end_ts'] = dt.astimezone(timezone.utc).isoformat()
            else:
                appt['end_ts'] = appt['end_ts'].astimezone(timezone.utc).isoformat()
        # Convert Decimal numeric to float
        if 'total_amount' in appt:
            try:
                appt['total_amount'] = float(appt['total_amount'])
            except Exception:
                pass

    return _ok({"appointments": appointments, "nextCursor": next_cursor})

@app.route("/api/admin/appointments", methods=["POST"])
def create_appointment():
    body = request.get_json(silent=True) or {}

    # Minimal required fields; defaults for S1
    status = norm_status(str(body.get("status", "SCHEDULED")))
    start_val = body.get("start")
    if isinstance(start_val, str):
        # Allow ISO8601 string
        try:
            start_dt = datetime.fromisoformat(start_val.replace("Z", "+00:00"))
        except Exception:
            return _fail(HTTPStatus.BAD_REQUEST, "INVALID_PARAM", "start must be ISO8601 timestamp")
    elif start_val is None:
        start_dt = utcnow()
    else:
        start_dt = start_val  # assume datetime

    total_amount = body.get("total_amount", 0) or 0
    paid_amount = body.get("paid_amount", 0) or 0

    conn = db_conn()
    if conn is None:
        # DB unavailable in memory mode â€” signal service unavailable for create
        return _fail(HTTPStatus.SERVICE_UNAVAILABLE, "DB_UNAVAILABLE", "Database unavailable")

    new_id = None
    with conn:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute(
                """
                INSERT INTO appointments (status, start_ts, total_amount, paid_amount)
                VALUES (%s, %s, %s, %s)
                RETURNING id
                """,
                (status, start_dt, total_amount, paid_amount),
            )
            row = cur.fetchone()
            new_id = str(row["id"]) if row else None
    conn.close()

    if not new_id:
        return _fail(HTTPStatus.INTERNAL_SERVER_ERROR, "CREATE_FAILED", "Failed to create appointment")

    return jsonify({"id": new_id}), 201


# PATCH endpoint for updating appointment status
@app.route("/api/admin/appointments/<appt_id>/status", methods=["PATCH"])
def update_appointment_status(appt_id: str):
    body = request.get_json(silent=True) or {}
    try:
        new_status = norm_status(str(body.get("status", "")))
    except BadRequest as e:
        return _fail(HTTPStatus.BAD_REQUEST, "INVALID_STATUS", str(e))

    conn = db_conn()
    if conn is None:
        # In memory mode, just acknowledge for UI flow
        return jsonify({"id": appt_id, "status": new_status})

    with conn:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute("SELECT id::text, status::text FROM appointments WHERE id = %s", (appt_id,))
            row = cur.fetchone()
            if not row:
                return _fail(HTTPStatus.NOT_FOUND, "NOT_FOUND", "Appointment not found")
            old_status = row["status"]
            if new_status not in ALLOWED_TRANSITIONS.get(old_status, set()):
                return _fail(HTTPStatus.BAD_REQUEST, "INVALID_TRANSITION", f"{old_status} -> {new_status} not allowed")
            cur.execute("UPDATE appointments SET status = %s WHERE id = %s RETURNING id", (new_status, appt_id))
            audit(conn, "system", "STATUS_CHANGE", "appointment", appt_id, {"status": old_status}, {"status": new_status})
    conn.close()
    return jsonify({"id": appt_id, "status": new_status})

# ----------------------------------------------------------------------------
# Services CRUD (S2)
# ----------------------------------------------------------------------------
@app.route("/api/appointments/<appt_id>/services", methods=["GET"])
def get_appointment_services(appt_id: str):
    """Get all services for an appointment."""
    conn = db_conn()
    if conn is None:
        return jsonify({"services": []})

    with conn:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute(
                """
                SELECT id::text, appointment_id::text, name, notes, 
                       estimated_hours, estimated_price, category, created_at
                FROM appointment_services 
                WHERE appointment_id = %s 
                ORDER BY created_at
                """,
                (appt_id,)
            )
            services = cur.fetchall()

    conn.close()
    return jsonify({
        "services": [
            {
                "id": s["id"],
                "appointment_id": s["appointment_id"],
                "name": s["name"],
                "notes": s.get("notes"),
                "estimated_hours": float(s["estimated_hours"]) if s.get("estimated_hours") is not None else None,
                "estimated_price": float(s["estimated_price"]) if s.get("estimated_price") is not None else None,
                "category": s.get("category"),
                "created_at": s["created_at"].isoformat() if s.get("created_at") else None,
            }
            for s in services
        ]
    })


@app.route("/api/appointments/<appt_id>/services", methods=["POST"])
def create_appointment_service(appt_id: str):
    """Create a new service for an appointment."""
    body = request.get_json(silent=True) or {}
    
    # Validate required fields
    name = body.get("name", "").strip()
    if not name:
        return _fail(HTTPStatus.BAD_REQUEST, "VALIDATION_FAILED", "Service name is required")
    
    notes = body.get("notes", "").strip()
    estimated_hours = body.get("estimated_hours")
    estimated_price = body.get("estimated_price")
    category = body.get("category", "").strip()
    
    # Convert numeric fields
    try:
        if estimated_hours is not None:
            estimated_hours = float(estimated_hours)
        if estimated_price is not None:
            estimated_price = float(estimated_price)
    except ValueError:
        return _fail(HTTPStatus.BAD_REQUEST, "VALIDATION_FAILED", "Invalid numeric values")

    conn = db_conn()
    if conn is None:
        # Legacy flat error for CSV endpoints
        return jsonify({"error_code": "DB_UNAVAILABLE", "detail": "Database unavailable"}), HTTPStatus.SERVICE_UNAVAILABLE

    new_service_id = None
    with conn:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            # Verify appointment exists
            cur.execute("SELECT id FROM appointments WHERE id = %s", (appt_id,))
            if not cur.fetchone():
                return _fail(HTTPStatus.NOT_FOUND, "NOT_FOUND", "Appointment not found")
            
            # Create service
            cur.execute(
                """
                INSERT INTO appointment_services (appointment_id, name, notes, estimated_hours, estimated_price, category)
                VALUES (%s, %s, %s, %s, %s, %s)
                RETURNING id::text
                """,
                (appt_id, name, notes or None, estimated_hours, estimated_price, category or None)
            )
            row = cur.fetchone()
            new_service_id = row["id"] if row else None
            
            # Recompute appointment total
            _recompute_appointment_total(cur, appt_id)
            
    conn.close()
    
    if not new_service_id:
        return _fail(HTTPStatus.INTERNAL_SERVER_ERROR, "CREATE_FAILED", "Failed to create service")
    
    return jsonify({"id": new_service_id}), 201


@app.route("/api/appointments/<appt_id>/services/<service_id>", methods=["PATCH"])
def update_appointment_service(appt_id: str, service_id: str):
    """Update an existing service."""
    body = request.get_json(silent=True) or {}
    
    # Build update fields
    updates = {}
    if "name" in body:
        name = body["name"].strip()
        if not name:
            return _fail(HTTPStatus.BAD_REQUEST, "VALIDATION_FAILED", "Service name cannot be empty")
        updates["name"] = name
    
    if "notes" in body:
        updates["notes"] = body["notes"].strip() or None
    
    if "estimated_hours" in body:
        try:
            updates["estimated_hours"] = float(body["estimated_hours"]) if body["estimated_hours"] is not None else None
        except ValueError:
            return _fail(HTTPStatus.BAD_REQUEST, "VALIDATION_FAILED", "Invalid estimated_hours value")
    
    if "estimated_price" in body:
        try:
            updates["estimated_price"] = float(body["estimated_price"]) if body["estimated_price"] is not None else None
        except ValueError:
            return _fail(HTTPStatus.BAD_REQUEST, "VALIDATION_FAILED", "Invalid estimated_price value")
    
    if "category" in body:
        updates["category"] = body["category"].strip() or None
    
    if not updates:
        return _fail(HTTPStatus.BAD_REQUEST, "VALIDATION_FAILED", "No valid fields to update")

    conn = db_conn()
    if conn is None:
        # Legacy flat error for CSV endpoints
        return jsonify({"error_code": "DB_UNAVAILABLE", "detail": "Database unavailable"}), HTTPStatus.SERVICE_UNAVAILABLE

    with conn:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            # Build dynamic update query
            set_parts = []
            values = []
            for field, value in updates.items():
                set_parts.append(f"{field} = %s")
                values.append(value)
            
            values.extend([service_id, appt_id])
            
            cur.execute(
                f"""
                UPDATE appointment_services 
                SET {', '.join(set_parts)}
                WHERE id = %s AND appointment_id = %s
                RETURNING id::text
                """,
                values
            )
            
            if not cur.fetchone():
                return _fail(HTTPStatus.NOT_FOUND, "NOT_FOUND", "Service not found")
            
            # Recompute appointment total
            _recompute_appointment_total(cur, appt_id)
    
    conn.close()
    return jsonify({"id": service_id})


@app.route("/api/appointments/<appt_id>/services/<service_id>", methods=["DELETE"])
def delete_appointment_service(appt_id: str, service_id: str):
    """Delete a service from an appointment."""
    conn = db_conn()
    if conn is None:
        return _fail(HTTPStatus.SERVICE_UNAVAILABLE, "DB_UNAVAILABLE", "Database unavailable")

    with conn:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute(
                "DELETE FROM appointment_services WHERE id = %s AND appointment_id = %s RETURNING id::text",
                (service_id, appt_id)
            )
            
            if not cur.fetchone():
                return _fail(HTTPStatus.NOT_FOUND, "NOT_FOUND", "Service not found")
            
            # Recompute appointment total
            _recompute_appointment_total(cur, appt_id)
    
    conn.close()
    return "", 204


def _recompute_appointment_total(cur, appt_id: str):
    """Recompute appointment total_amount from services."""
    cur.execute(
        """
        UPDATE appointments 
        SET total_amount = (
            SELECT COALESCE(SUM(estimated_price), 0) 
            FROM appointment_services 
            WHERE appointment_id = %s
        )
        WHERE id = %s
        """,
        (appt_id, appt_id)
    )

# ----------------------------------------------------------------------------
# Messaging (T-021)
# ----------------------------------------------------------------------------
@app.route("/api/appointments/<appt_id>/messages", methods=["GET"])
def get_appointment_messages(appt_id: str):
    """Get all messages for an appointment."""
    # TODO: Re-enable authentication after fixing frontend auth flow
    # For now, skip auth to allow History tab to work
    # try:
    #     user = require_auth_role()
    #     user_role = user.get("role", "Advisor")
    # except Exception:
    #     return _fail(HTTPStatus.FORBIDDEN, "AUTH_REQUIRED", "Authentication required")

    conn = db_conn()
    if conn is None:
        return _fail(HTTPStatus.SERVICE_UNAVAILABLE, "DB_UNAVAILABLE", "Database unavailable")

    # Check if we're using SQLite fallback
    using_sqlite = type(conn).__name__ == 'SqliteConnectionWrapper'
    
    if using_sqlite:
        # SQLite compatible query
        with conn:
            cursor = conn.cursor()
            # Verify appointment exists
            cursor.execute("SELECT id FROM appointments WHERE id = ?", (appt_id,))
            if not cursor.fetchone():
                return _fail(HTTPStatus.NOT_FOUND, "NOT_FOUND", "Appointment not found")
            
            # For now, return empty messages since messages table doesn't exist in SQLite
            # TODO: Create messages table in SQLite schema
            return _ok({"messages": []})
    else:
        # PostgreSQL query (original)
        with conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                # Verify appointment exists
                cur.execute("SELECT id FROM appointments WHERE id = %s", (appt_id,))
                if not cur.fetchone():
                    return _fail(HTTPStatus.NOT_FOUND, "NOT_FOUND", "Appointment not found")
                
                # Get messages ordered by timestamp (latest first)
                cur.execute(
                    """
                    SELECT id::text, appointment_id::text, channel, direction, body, 
                           status, sent_at
                    FROM messages 
                    WHERE appointment_id = %s
                    ORDER BY sent_at DESC
                    """,
                    (appt_id,)
                )
                messages = cur.fetchall()

        conn.close()
        return _ok({
            "messages": [
                {
                    "id": m["id"],
                    "appointment_id": m["appointment_id"],
                    "channel": m["channel"],
                    "direction": m["direction"],
                    "body": m["body"],
                    "status": m["status"],
                    "sent_at": m["sent_at"].isoformat() if m.get("sent_at") else None,
                }
                for m in messages
            ]
        })


@app.route("/api/appointments/<appt_id>/messages", methods=["POST"])
def create_appointment_message(appt_id: str):
    """Create a new outbound message for an appointment."""
    # Role check: Owner & Advisor can write, Tech read-only
    try:
        user = require_auth_role()
        user_role = user.get("role", "Advisor")
        if user_role not in ["Owner", "Advisor"]:
            return _fail(HTTPStatus.FORBIDDEN, "RBAC_FORBIDDEN", "Only Owner and Advisor can send messages")
    except Exception:
        return _fail(HTTPStatus.FORBIDDEN, "AUTH_REQUIRED", "Authentication required")

    body = request.get_json(silent=True) or {}
    
    # Validate required fields
    channel = body.get("channel", "").strip().lower()
    if channel not in ["sms", "email"]:
        return _fail(HTTPStatus.BAD_REQUEST, "VALIDATION_FAILED", "Channel must be 'sms' or 'email'")
    
    message_body = body.get("body", "").strip()
    if not message_body:
        return _fail(HTTPStatus.BAD_REQUEST, "VALIDATION_FAILED", "Message body is required")

    conn = db_conn()
    if conn is None:
        return _fail(HTTPStatus.SERVICE_UNAVAILABLE, "DB_UNAVAILABLE", "Database unavailable")

    new_message_id = None
    with conn:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            # Verify appointment exists
            cur.execute("SELECT id FROM appointments WHERE id = %s", (appt_id,))
            if not cur.fetchone():
                return _fail(HTTPStatus.NOT_FOUND, "NOT_FOUND", "Appointment not found")
            
            # Create outbound message with 'queued' status
            cur.execute(
                """
                INSERT INTO messages (appointment_id, channel, direction, body, status)
                VALUES (%s, %s, 'out', %s, 'sending')
                RETURNING id::text
                """,
                (appt_id, channel, message_body)
            )
            row = cur.fetchone()
            new_message_id = row["id"] if row else None
            
            # Audit log
            audit(conn, user.get("sub", "system"), "MESSAGE_SENT", "message", new_message_id or "unknown", 
                  {}, {"appointment_id": appt_id, "channel": channel, "direction": "out"})
            
    conn.close()
    
    if not new_message_id:
        return _fail(HTTPStatus.INTERNAL_SERVER_ERROR, "CREATE_FAILED", "Failed to create message")
    
    return _ok({"id": new_message_id, "status": "sending"}, HTTPStatus.CREATED)


@app.route("/api/appointments/<appt_id>/messages/<message_id>", methods=["PATCH"])
def update_message_status(appt_id: str, message_id: str):
    """Update message delivery status (typically from webhook or manual retry)."""
    # Role check: Owner & Advisor can update
    try:
        user = require_auth_role()
        user_role = user.get("role", "Advisor")
        if user_role not in ["Owner", "Advisor"]:
            return _fail(HTTPStatus.FORBIDDEN, "RBAC_FORBIDDEN", "Only Owner and Advisor can update messages")
    except Exception:
        return _fail(HTTPStatus.FORBIDDEN, "AUTH_REQUIRED", "Authentication required")

    body = request.get_json(silent=True) or {}
    
    # Build update fields
    updates = {}
    if "status" in body:
        status = body["status"].strip().lower()
        if status not in ["sending", "delivered", "failed"]:
            return _fail(HTTPStatus.BAD_REQUEST, "VALIDATION_FAILED", "Status must be 'sending', 'delivered', or 'failed'")
        updates["status"] = status
    
    if not updates:
        return _fail(HTTPStatus.BAD_REQUEST, "VALIDATION_FAILED", "No valid fields to update")

    conn = db_conn()
    if conn is None:
        return _fail(HTTPStatus.SERVICE_UNAVAILABLE, "DB_UNAVAILABLE", "Database unavailable")

    with conn:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            # Build dynamic update query
            set_parts = []
            values = []
            for field, value in updates.items():
                set_parts.append(f"{field} = %s")
                values.append(value)
            
            values.extend([message_id, appt_id])
            
            cur.execute(
                f"""
                UPDATE messages 
                SET {', '.join(set_parts)}
                WHERE id = %s AND appointment_id = %s
                RETURNING id::text
                """,
                values
            )
            
            if not cur.fetchone():
                return _fail(HTTPStatus.NOT_FOUND, "NOT_FOUND", "Message not found")
            
            # Audit log
            audit(conn, user.get("sub", "system"), "MESSAGE_UPDATED", "message", message_id, 
                  {}, updates)
    
    conn.close()
    return _ok({"id": message_id})


@app.route("/api/appointments/<appt_id>/messages/<message_id>", methods=["DELETE"])
def delete_appointment_message(appt_id: str, message_id: str):
    """Delete a message from an appointment."""
    # Role check: Owner & Advisor can delete
    try:
        user = require_auth_role()
        user_role = user.get("role", "Advisor")
        if user_role not in ["Owner", "Advisor"]:
            return _fail(HTTPStatus.FORBIDDEN, "RBAC_FORBIDDEN", "Only Owner and Advisor can delete messages")
    except Exception:
        return _fail(HTTPStatus.FORBIDDEN, "AUTH_REQUIRED", "Authentication required")

    conn = db_conn()
    if conn is None:
        return _fail(HTTPStatus.SERVICE_UNAVAILABLE, "DB_UNAVAILABLE", "Database unavailable")

    with conn:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            # Hard delete since no deleted_at column in current schema
            cur.execute(
                "DELETE FROM messages WHERE id = %s AND appointment_id = %s RETURNING id::text",
                (message_id, appt_id)
            )
            
            if not cur.fetchone():
                return _fail(HTTPStatus.NOT_FOUND, "NOT_FOUND", "Message not found")
            
            # Audit log
            audit(conn, user.get("sub", "system"), "MESSAGE_DELETED", "message", message_id, 
                  {"deleted": False}, {"deleted": True})
    
    conn.close()
    return "", 204

# ----------------------------------------------------------------------------
# Customer History (T-023)
# ----------------------------------------------------------------------------
@app.route("/api/customers/<customer_id>/history", methods=["GET"])
def get_customer_history(customer_id: str):
    """Get customer's appointment and payment history."""
    # Require authentication (tests expect auth enforced)
    try:
        user = require_auth_role()
        user_role = user.get("role", "Advisor")
        if user_role not in ["Owner", "Advisor"]:
            return _fail(HTTPStatus.FORBIDDEN, "RBAC_FORBIDDEN", "Only Owner and Advisor can view customer history")
    except Exception:
        return _fail(HTTPStatus.FORBIDDEN, "AUTH_REQUIRED", "Authentication required")

    conn = db_conn()
    if conn is None:
        return _fail(HTTPStatus.SERVICE_UNAVAILABLE, "DB_UNAVAILABLE", "Database unavailable")

    # Check if we're using SQLite fallback
    using_sqlite = type(conn).__name__ == 'SqliteConnectionWrapper'
    
    if using_sqlite:
        # SQLite compatible query
        with conn:
            cursor = conn.cursor()
            # Verify customer exists
            cursor.execute("SELECT id, name FROM customers WHERE id = ?", (customer_id,))
            customer = cursor.fetchone()
            if not customer:
                return _fail(HTTPStatus.NOT_FOUND, "NOT_FOUND", "Customer not found")
            
            # Get past appointments - SQLite compatible (no JSON functions)
            cursor.execute(
                """
                SELECT 
                    CAST(a.id AS TEXT) as id,
                    a.status, 
                    a.start_ts,
                    COALESCE(a.total_amount, 0) as total_amount,
                    COALESCE(a.paid_amount, 0) as paid_amount,
                    a.created_at as appointment_created_at
                FROM appointments a
                WHERE a.customer_id = ? 
                    AND a.status IN ('COMPLETED', 'NO_SHOW', 'CANCELED')
                ORDER BY a.start_ts DESC, a.id DESC
                """,
                (customer_id,)
            )
            appointments = cursor.fetchall()
            
            # For SQLite, return simplified structure without payments for now
            # TODO: Add payments table support to SQLite schema
            past_appointments = []
            for appt in appointments:
                past_appointments.append({
                    "id": appt[0],  # id
                    "status": appt[1],  # status
                    "start": appt[2] if appt[2] else None,  # start_ts
                    "total_amount": float(appt[3]) if appt[3] else 0.0,
                    "paid_amount": float(appt[4]) if appt[4] else 0.0,
                    "created_at": appt[5] if appt[5] else None,
                    "payments": []  # Empty for SQLite fallback
                })
            
            return _ok({
                "pastAppointments": past_appointments,
                "payments": []
            })
    else:
        # PostgreSQL query (original)
        with conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                # Verify customer exists
                cur.execute("SELECT id, name FROM customers WHERE id = %s", (customer_id,))
                customer = cur.fetchone()
                if not customer:
                    return _fail(HTTPStatus.NOT_FOUND, "NOT_FOUND", "Customer not found")
                
                # Get past appointments with payments using LEFT JOIN
                # Use JSON_AGG/JSON_BUILD_OBJECT in Postgres; tests expect that shape.
                cur.execute(
                    """
                    SELECT 
                        a.id::text, 
                        a.status::text, 
                        a.start_ts,
                        a.total_amount,
                        a.paid_amount,
                        a.created_at as appointment_created_at,
                        COALESCE(
                            JSON_AGG(
                                JSON_BUILD_OBJECT(
                                    'id', p.id::text,
                                    'amount', p.amount,
                                    'method', p.method,
                                    'created_at', p.created_at
                                ) ORDER BY p.created_at DESC
                            ) FILTER (WHERE p.id IS NOT NULL), 
                            '[]'::json
                        ) as payments
                    FROM appointments a
                    LEFT JOIN payments p ON p.appointment_id = a.id
                    WHERE a.customer_id = %s 
                        AND a.status IN ('COMPLETED', 'NO_SHOW', 'CANCELED')
                    GROUP BY a.id, a.status, a.start_ts, a.total_amount, a.paid_amount, a.created_at
                    ORDER BY a.start_ts DESC, a.id DESC
                    """,
                    (customer_id,)
                )
                appointments = cur.fetchall()

        conn.close()
        
        # Format appointments for response
        past_appointments = []
        for appt in appointments:
            past_appointments.append({
                "id": appt["id"],
                "status": appt["status"],
                "start": appt["start_ts"].isoformat() if appt.get("start_ts") else None,
                "total_amount": float(appt["total_amount"]) if appt.get("total_amount") else 0.0,
                "paid_amount": float(appt["paid_amount"]) if appt.get("paid_amount") else 0.0,
                "created_at": appt["appointment_created_at"].isoformat() if appt.get("appointment_created_at") else None,
                "payments": appt["payments"] if appt.get("payments") else []
            })

        return _ok({
            "pastAppointments": past_appointments,
            "payments": []  # payments are now nested in appointments
        })

# ----------------------------------------------------------------------------
# Stats & Cars
# ----------------------------------------------------------------------------
@app.route("/api/admin/dashboard/stats", methods=["GET"])
def stats():
    # optional auth in S1
    try:
        require_auth_role()
    except Exception:
        pass

    # Check Redis cache first (30s TTL)
    cache_key = "dashboard_stats"
    cached_result = redis_get(cache_key)
    if cached_result:
        try:
            return jsonify(json.loads(cached_result))
        except Exception as e:
            log.warning("Failed to parse cached stats: %s", e)

    frm = request.args.get("from")
    to = request.args.get("to")

    conn = db_conn()
    if conn is None:
        # Fallback stats when DB is unavailable
        fallback_stats = {
            "jobsToday": 0,
            "carsOnPremises": 0,
            "scheduled": 0,
            "inProgress": 0,
            "ready": 0,
            "completed": 0,
            "noShow": 0,
            "unpaidTotal": 0.0,
            "totals": {
                "today_completed": 0,
                "today_booked": 0,
                "avg_cycle": None,
                "avg_cycle_formatted": "N/A"
            }
        }
        return jsonify(fallback_stats)

    today = date.today()
    with conn:
        with conn.cursor() as cur:
            # counts by status
            cur.execute("SELECT status::text, COUNT(*) FROM appointments GROUP BY status")
            results = cur.fetchall()
            # Build counts mapping, handling dict or tuple rows
            counts = {}
            for r in results:
                if isinstance(r, dict):
                    key = r.get('status')
                    val = r.get('count', 0)
                else:
                    key = r[0] if len(r) > 0 else None
                    val = r[1] if len(r) > 1 else 0
                try:
                    counts[key] = int(val)
                except Exception:
                    counts[key] = 0

            # cars on premises
            cur.execute("SELECT COUNT(*) FROM appointments WHERE check_in_at IS NOT NULL AND check_out_at IS NULL")
            cars_result = cur.fetchone()
            cars = 0
            if cars_result:
                try:
                    # Handle both dict (RealDictCursor) and tuple results
                    if isinstance(cars_result, dict):
                        cars = int(cars_result.get('count', 0))
                    else:
                        cars = int(cars_result[0]) if len(cars_result) > 0 else 0
                except (IndexError, TypeError, ValueError):
                    cars = 0

            # jobs today (based on canonical start_ts)
            cur.execute("SELECT COUNT(*) FROM appointments WHERE start_ts::date = %s", (today,))
            jobs_result = cur.fetchone()
            jobs_today = 0
            if jobs_result:
                try:
                    if isinstance(jobs_result, dict):
                        jobs_today = int(jobs_result.get('count', 0))
                    else:
                        jobs_today = int(jobs_result[0]) if len(jobs_result) > 0 else 0
                except (IndexError, TypeError, ValueError):
                    jobs_today = 0

            # unpaid total
            cur.execute("SELECT COALESCE(SUM(COALESCE(total_amount,0) - COALESCE(paid_amount,0)),0) FROM appointments")
            unpaid_result = cur.fetchone()
            unpaid = 0.0
            if unpaid_result:
                try:
                    if isinstance(unpaid_result, dict):
                        unpaid = float(unpaid_result.get('coalesce', 0))
                    else:
                        unpaid = float(unpaid_result[0]) if len(unpaid_result) > 0 else 0.0
                except (IndexError, TypeError, ValueError):
                    unpaid = 0.0

            # NEW METRICS FOR v2

            # today_completed - completed appointments today
            cur.execute("""
                SELECT COUNT(*) FROM appointments 
                WHERE start_ts::date = %s AND status = 'COMPLETED'
            """, (today,))
            completed_result = cur.fetchone()
            today_completed = 0
            if completed_result:
                try:
                    if isinstance(completed_result, dict):
                        today_completed = int(completed_result.get('count', 0))
                    else:
                        today_completed = int(completed_result[0]) if len(completed_result) > 0 else 0
                except (IndexError, TypeError, ValueError):
                    today_completed = 0

            # today_booked - all appointments scheduled for today (regardless of status)
            # This is the same as jobs_today but more explicit
            today_booked = jobs_today

            # avg_cycle_time - average time from start to completion (in hours)
            cur.execute("""
                SELECT AVG(EXTRACT(EPOCH FROM end_ts - start_ts)) / 3600 as avg_hours
                FROM appointments 
                WHERE end_ts IS NOT NULL AND start_ts IS NOT NULL
                  AND status = 'COMPLETED'
                  AND start_ts >= %s
            """, (today - timedelta(days=30),))  # Last 30 days for better average
            
            avg_result = cur.fetchone()
            avg_cycle_hours = None
            if avg_result:
                try:
                    if isinstance(avg_result, dict):
                        avg_cycle_hours = float(avg_result.get('avg_hours', 0)) if avg_result.get('avg_hours') is not None else None
                    else:
                        avg_cycle_hours = float(avg_result[0]) if len(avg_result) > 0 and avg_result[0] is not None else None
                except (IndexError, TypeError, ValueError):
                    avg_cycle_hours = None

    conn.close()
    
    # Build enhanced response structure
    response_data = {
        # Legacy fields for backward compatibility
        "jobsToday": jobs_today,
        "carsOnPremises": cars,
        "scheduled": counts.get("SCHEDULED", 0),
        "inProgress": counts.get("IN_PROGRESS", 0),
        "ready": counts.get("READY", 0),
        "completed": counts.get("COMPLETED", 0),
        "noShow": counts.get("NO_SHOW", 0),
        "unpaidTotal": round(unpaid, 2),
        
        # NEW: Enhanced totals object for v2
        "totals": {
            "today_completed": today_completed,
            "today_booked": today_booked,
            "avg_cycle": avg_cycle_hours,
            "avg_cycle_formatted": format_duration_hours(avg_cycle_hours) if avg_cycle_hours else "N/A"
        }
    }

    # Cache result for 30 seconds
    redis_set(cache_key, json.dumps(response_data), ex=30)
    
    return jsonify(response_data)


@app.route("/api/admin/cars-on-premises", methods=["GET"])
def cars_on_premises():
    conn = db_conn()
    if conn is None:
        return jsonify({"cars_on_premises": []})

    with conn:
        with conn.cursor() as cur:
            cur.execute(
                """
                SELECT a.id::text,
                       a.check_in_at,
                       c.name AS owner,
                       v.year, v.make, v.model
                FROM appointments a
                LEFT JOIN customers c ON c.id = a.customer_id
                LEFT JOIN vehicles v  ON v.id = a.vehicle_id
                WHERE a.check_in_at IS NOT NULL AND a.check_out_at IS NULL
                ORDER BY a.check_in_at ASC
                """
            )
            rows = cur.fetchall()

    conn.close()
    out = []
    for r in rows:
        out.append(
            {
                "id": r["id"],
                "owner": r.get("owner") or "",
                "make": r.get("make") or "",
                "model": r.get("model") or "",
                "arrivalTime": r["check_in_at"].astimezone(timezone.utc).isoformat() if r.get("check_in_at") else None,
                "status": "IN_PROGRESS",
                "pickupTime": None,
            }
        )
    return jsonify({"cars_on_premises": out})

# ----------------------------------------------------------------------------
# Wrap admin appointments GET responses to ensure envelope shape
@app.after_request
def wrap_admin_appointments(response):
    if request.path == "/api/admin/appointments" and request.method == "GET":
        try:
            orig = response.get_json(silent=True)
        except Exception:
            return response
        # Already enveloped?
        if isinstance(orig, dict) and any(k in orig for k in ("data", "errors", "meta")):
            return response
        # Return a Response object (avoid returning a tuple which breaks other after_request handlers)
        new_resp = jsonify({"data": orig, "errors": None, "meta": {"request_id": _req_id()}})
        new_resp.status_code = response.status_code
        return new_resp
    return response

# ----------------------------------------------------------------------------
# CSV Export
# ----------------------------------------------------------------------------
@app.route("/api/admin/appointments/export", methods=["GET"])
def export_appointments():
    """Export appointments to CSV."""
    # Role check: Owner & Advisor only
    try:
        user = require_auth_role()
        user_role = user.get("role", "Advisor")
        if user_role not in ["Owner", "Advisor"]:
            return _fail(HTTPStatus.FORBIDDEN, "RBAC_FORBIDDEN", "Only Owner and Advisor can export appointments")
    except Exception:
        return _fail(HTTPStatus.FORBIDDEN, "AUTH_REQUIRED", "Authentication required")

    # Query parameters
    frm = request.args.get("from")
    to = request.args.get("to")
    tech_id = request.args.get("techId")
    status = request.args.get("status")

    # Validate and normalize status
    if status:
        try:
            status = norm_status(status)
        except BadRequest:
            return _fail(HTTPStatus.BAD_REQUEST, "INVALID_STATUS", "Invalid status value")

    conn = db_conn()
    if conn is None:
        # Legacy flat error for CSV endpoints
        return jsonify({"error_code": "DB_UNAVAILABLE", "detail": "Database unavailable"}), HTTPStatus.SERVICE_UNAVAILABLE

    try:
        with conn:
            with conn.cursor() as cur, io.StringIO() as csv_output:
                # Write CSV header
                writer = csv.writer(csv_output)
                writer.writerow([
                    "ID", "Status", "Start", "End", "Total Amount", "Paid Amount",
                    "Customer Name", "Customer Email", "Customer Phone",
                    "Vehicle Year", "Vehicle Make", "Vehicle Model", "Vehicle VIN",
                    "Services"
                ])

                # Filtered query for appointments
                where = ["1=1"]
                params: list[Any] = []
                if frm:
                    where.append("a.start_ts >= %s")
                    params.append(frm)
                if to:
                    where.append("a.end_ts <= %s")
                    params.append(to)
                if tech_id:
                    where.append("a.tech_id = %s")
                    params.append(tech_id)
                if status:
                    where.append("a.status = %s")
                    params.append(status)

                where_sql = " AND ".join(where)

                cur.execute(
                    f"""
                    SELECT a.id::text, a.status::text, a.start_ts, a.end_ts,
                           COALESCE(a.total_amount, 0) AS total_amount,
                           COALESCE(a.paid_amount, 0) AS paid_amount,
                           c.name AS customer_name, c.email AS customer_email, c.phone AS customer_phone,
                           v.year, v.make, v.model, v.vin,
                           SUBSTRING((SELECT STRING_AGG(sv.name, ', ')
                                      FROM appointment_services sv WHERE sv.appointment_id = a.id)::text FROM 1 FOR 120) AS services_summary
                    FROM appointments a
                    LEFT JOIN customers c ON c.id = a.customer_id
                    LEFT JOIN vehicles v  ON v.id = a.vehicle_id
                    WHERE {where_sql}
                    ORDER BY a.start_ts
                    """,
                    params,
                )
                rows = cur.fetchall()

                # Write data rows
                for r in rows:
                    writer.writerow([
                        r["id"],
                        r["status"],
                        r["start_ts"].isoformat() if r["start_ts"] else None,
                        r["end_ts"].isoformat() if r["end_ts"] else None,
                        float(r["total_amount"]) if r["total_amount"] is not None else 0.0,
                        float(r["paid_amount"]) if r["paid_amount"] is not None else 0.0,
                        r.get("customer_name"),
                        r.get("customer_email"),
                        r.get("customer_phone"),
                        r.get("year"),
                        r.get("make"),
                        r.get("model"),
                        r.get("vin"),
                        r.get("services_summary"),
                    ])

                # Seek to beginning of StringIO buffer
                csv_output.seek(0)

                # Return CSV response
                return Response(
                    csv_output.getvalue(),
                    mimetype="text/csv",
                    headers={"Content-Disposition": "attachment;filename=appointments_export.csv"},
                )
    finally:
        conn.close()

# ----------------------------------------------------------------------------
# Payments CSV Export (T-022)
# ----------------------------------------------------------------------------
@app.route("/api/admin/payments/export", methods=["GET"])
def export_payments():
    """Export payments to CSV."""
    # Role check: Owner & Advisor only
    try:
        user = require_auth_role()
        user_role = user.get("role", "Advisor")
        if user_role not in ["Owner", "Advisor"]:
            return _fail(HTTPStatus.FORBIDDEN, "RBAC_FORBIDDEN", "Only Owner and Advisor can export payments")
    except Exception:
        # Legacy clients expect a flat error object for CSV endpoints
        return jsonify({"error_code": "AUTH_REQUIRED", "detail": "Authentication required"}), HTTPStatus.FORBIDDEN

    # Query parameters
    frm = request.args.get("from")
    to = request.args.get("to")
    appt_id = request.args.get("appointmentId")

    conn = db_conn()
    if conn is None:
        # Legacy flat error for CSV endpoints
        return jsonify({"error_code": "DB_UNAVAILABLE", "detail": "Database unavailable"}), HTTPStatus.SERVICE_UNAVAILABLE

    try:
        with conn:
            with conn.cursor() as cur, io.StringIO() as csv_output:
                # Write CSV header
                writer = csv.writer(csv_output)
                writer.writerow([
                    "ID", "Appointment ID", "Amount", "Method", "Status", "Created At"
                ])

                # Filtered query for payments
                where = ["1=1"]
                params: list[Any] = []
                if frm:
                    where.append("p.created_at >= %s")
                    params.append(frm)
                if to:
                    where.append("p.created_at <= %s")
                    params.append(to)
                if appt_id:
                    where.append("p.appointment_id = %s")
                    params.append(appt_id)

                where_sql = " AND ".join(where)

                cur.execute(
                    f"""
                    SELECT p.id::text, p.appointment_id::text, p.amount, p.method, p.status, p.created_at
                    FROM payments p
                    WHERE {where_sql}
                    ORDER BY p.created_at
                    """,
                    params,
                )
                rows = cur.fetchall()

                # Write data rows
                for r in rows:
                    writer.writerow([
                        r["id"],
                        r["appointment_id"],
                        float(r["amount"]) if r["amount"] is not None else 0.0,
                        r.get("method"),
                        r.get("status"),
                        r["created_at"].isoformat() if r["created_at"] else None,
                    ])

                # Seek to beginning of StringIO buffer
                csv_output.seek(0)

                # Return CSV response
                return Response(
                    csv_output.getvalue(),
                    mimetype="text/csv",
                    headers={"Content-Disposition": "attachment;filename=payments_export.csv"},
                )
    finally:
        conn.close()
# ----------------------------------------------------------------------------
# CSV Export Endpoints (T-024)
# ----------------------------------------------------------------------------
@app.route("/api/admin/reports/appointments.csv", methods=["GET"])
def export_appointments_csv():
    """Export appointments as CSV file for accounting tools."""
    # RBAC: Owner/Advisor/Accountant only
    try:
        user = require_auth_role()
        user_role = user.get("role", "Advisor")
        if user_role not in ["Owner", "Advisor", "Accountant"]:
            # Legacy clients expect a flat error object for CSV endpoints
            return jsonify({"error_code": "RBAC_FORBIDDEN", "detail": "Only Owner, Advisor, and Accountant can export CSV"}), HTTPStatus.FORBIDDEN
    except Exception:
        # Legacy clients expect a flat error object for CSV endpoints
        return jsonify({"error_code": "AUTH_REQUIRED", "detail": "Authentication required"}), HTTPStatus.FORBIDDEN

    # Rate limiting for exports (5 per user per hour)
    user_id = user.get("user_id", user.get("sub", "unknown"))
    rate_limit_key = f"csv_export_{user_id}"
    try:
        rate_limit(rate_limit_key, 5, 3600)
    except Exception:
        return _fail(HTTPStatus.TOO_MANY_REQUESTS, "RATE_LIMIT", "Export rate limit exceeded")

    # Query parameter validation
    args = request.args
    from_date = args.get("from")
    to_date = args.get("to") 
    status_filter = args.get("status")

    # Validate date format if provided
    where_conditions = ["1=1"]
    params = []
    
    if from_date:
        try:
            datetime.fromisoformat(from_date.replace('Z', '+00:00'))
            where_conditions.append("a.start_ts >= %s")
            params.append(from_date)
        except ValueError:
            return jsonify({"error_code": "INVALID_DATE_FORMAT", "detail": "Invalid 'from' date format. Use ISO 8601 format."}), HTTPStatus.BAD_REQUEST
    
    if to_date:
        try:
            datetime.fromisoformat(to_date.replace('Z', '+00:00'))
            where_conditions.append("a.end_ts <= %s")
            params.append(to_date)
        except ValueError:
            return jsonify({"error_code": "INVALID_DATE_FORMAT", "detail": "Invalid 'to' date format. Use ISO 8601 format."}), HTTPStatus.BAD_REQUEST
    
    if status_filter:
        try:
            normalized_status = norm_status(status_filter)
            # Validate against known statuses
            if normalized_status not in {"SCHEDULED", "IN_PROGRESS", "READY", "COMPLETED", "NO_SHOW", "CANCELED"}:
                return jsonify({"error_code": "INVALID_STATUS", "detail": "Invalid status value"}), HTTPStatus.BAD_REQUEST
            where_conditions.append("a.status = %s")
            params.append(normalized_status)
        except BadRequest:
            return jsonify({"error_code": "INVALID_STATUS", "detail": "Invalid status value"}), HTTPStatus.BAD_REQUEST

    conn = db_conn()
    if conn is None:
        # Legacy flat error for CSV endpoints
        return jsonify({"error_code": "DB_UNAVAILABLE", "detail": "Database unavailable"}), HTTPStatus.SERVICE_UNAVAILABLE

    try:
        with conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                # Query appointments with customer and vehicle data
                query = """
                    SELECT 
                        a.id::text,
                        COALESCE(c.name, '') as customer,
                        COALESCE(v.year::text || ' ' || v.make || ' ' || v.model, '') as vehicle,
                        a.start_ts,
                        a.status::text,
                        COALESCE(a.total_amount, 0) as total_amount,
                        COALESCE(a.paid_amount, 0) as paid_amount
                    FROM appointments a
                    LEFT JOIN customers c ON c.id = a.customer_id
                    LEFT JOIN vehicles v ON v.id = a.vehicle_id
                    WHERE """ + " AND ".join(where_conditions) + """
                    ORDER BY a.start_ts DESC
                """
                cur.execute(query, params)
                appointments = cur.fetchall()

        # Generate CSV content
        output = io.StringIO()
        writer = csv.writer(output, quoting=csv.QUOTE_MINIMAL)
        
        # Write header row (RFC4180 compliant)
        writer.writerow([
            "ID", "Status", "Start", "End", "Total Amount", "Paid Amount",
            "Customer Name", "Customer Email", "Customer Phone",
            "Vehicle Year", "Vehicle Make", "Vehicle Model", "Vehicle VIN",
            "Services"
        ])
        
        # Write data rows (defensive access)
        for appointment in appointments:
            start_val = appointment.get('start_ts')
            if hasattr(start_val, 'isoformat'):
                start_str = start_val.isoformat()
            else:
                start_str = str(start_val) if start_val else ''
            writer.writerow([
                appointment.get('id', ''),
                appointment.get('status', ''),
                start_str,
                appointment.get('end_ts', '') if appointment.get('end_ts') else '',
                float(appointment.get('total_amount') or 0),
                float(appointment.get('paid_amount') or 0),
                appointment.get('customer_name', ''),
                appointment.get('customer_email', '') if appointment.get('customer_email') else '',
                appointment.get('customer_phone', '') if appointment.get('customer_phone') else '',
                appointment.get('year', '') if appointment.get('year') else '',
                appointment.get('make', '') if appointment.get('make') else '',
                appointment.get('model', '') if appointment.get('model') else '',
                appointment.get('vin', '') if appointment.get('vin') else '',
                appointment.get('services_summary', '') if appointment.get('services_summary') else '',
            ])

        csv_content = output.getvalue()
        output.close()

        # Create response with proper headers for file download
        response = Response(csv_content, mimetype='text/csv')
        response.headers['Content-Disposition'] = 'attachment;filename=appointments_export.csv'
        response.headers['Content-Type'] = 'text/csv; charset=utf-8'
        
        # Log the export for audit trail (simple signature expected by tests)
        audit_log(user_id, "CSV_EXPORT", {"appointments": True, "count": len(appointments)})
        
        return response

    except Exception as e:
        log.error("CSV export failed: %s", e)
        return _fail(HTTPStatus.INTERNAL_SERVER_ERROR, "EXPORT_FAILED", "CSV export failed")
    finally:
        try:
            conn.close()
        except AttributeError:
            pass


@app.route("/api/admin/reports/payments.csv", methods=["GET"])
def export_payments_csv():
    """Export payments as CSV file for accounting tools."""
    # RBAC: Owner/Advisor/Accountant only
    try:
        user = require_auth_role()
        user_role = user.get("role", "Advisor")
        if user_role not in ["Owner", "Advisor", "Accountant"]:
            return _fail(HTTPStatus.FORBIDDEN, "RBAC_FORBIDDEN", "Only Owner, Advisor, and Accountant can export CSV")
    except Exception:
        # Legacy clients expect a flat error object for CSV endpoints
        return jsonify({"error_code": "AUTH_REQUIRED", "detail": "Authentication required"}), HTTPStatus.FORBIDDEN

    # Rate limiting for exports
    user_id = user.get("user_id", user.get("sub", "unknown"))
    rate_limit_key = f"csv_export_{user_id}"
    try:
        rate_limit(rate_limit_key, 5, 3600)
    except Exception:
        return _fail(HTTPStatus.TOO_MANY_REQUESTS, "RATE_LIMIT", "Export rate limit exceeded")

    # Query parameter validation
    args = request.args
    from_date = args.get("from")
    to_date = args.get("to")

    where_conditions = ["1=1"]
    params = []
    
    if from_date:
        try:
            datetime.fromisoformat(from_date.replace('Z', '+00:00'))
            where_conditions.append("p.created_at >= %s")
            params.append(from_date)
        except ValueError:
            # Legacy clients expect flat error objects for CSV endpoints
            return jsonify({"error_code": "INVALID_DATE_FORMAT", "detail": "Invalid 'from' date format. Use ISO 8601 format."}), HTTPStatus.BAD_REQUEST
    
    if to_date:
        try:
            datetime.fromisoformat(to_date.replace('Z', '+00:00'))
            where_conditions.append("p.created_at <= %s")
            params.append(to_date)
        except ValueError:
            # Legacy clients expect flat error objects for CSV endpoints
            return jsonify({"error_code": "INVALID_DATE_FORMAT", "detail": "Invalid 'to' date format. Use ISO 8601 format."}), HTTPStatus.BAD_REQUEST

    conn = db_conn()
    if conn is None:
        # Legacy flat error for CSV endpoints
        return jsonify({"error_code": "DB_UNAVAILABLE", "detail": "Database unavailable"}), HTTPStatus.SERVICE_UNAVAILABLE

    try:
        with conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                # Query payments with appointment data
                query = """
                    SELECT 
                        p.id::text,
                        p.appointment_id::text,
                        p.amount,
                        p.method,
                        p.created_at
                    FROM payments p
                    WHERE """ + " AND ".join(where_conditions) + """
                    ORDER BY p.created_at DESC
                """
                cur.execute(query, params)
                payments = cur.fetchall()

        # Generate CSV content
        output = io.StringIO()
        writer = csv.writer(output, quoting=csv.QUOTE_MINIMAL)
        
        # Write header row (RFC4180 compliant)
        writer.writerow([
            "ID", "Appointment ID", "Amount", "Payment Method", "Transaction ID", "Payment Date", "Status"
        ])
        
        # Write data rows
        for payment in payments:
            writer.writerow([
                payment.get('id', ''),
                payment.get('appointment_id', ''),
                float(payment.get('amount') or 0),
                payment.get('method', ''),
                payment.get('transaction_id', ''),
                payment.get('created_at').isoformat() if payment.get('created_at') else '',
                payment.get('status', '')
            ])

        csv_content = output.getvalue()
        output.close()

        # Create response with proper headers for file download
        response = Response(csv_content, mimetype='text/csv')
        response.headers['Content-Disposition'] = 'attachment;filename=payments_export.csv'
        response.headers['Content-Type'] = 'text/csv; charset=utf-8'
        
        # Log the export for audit trail (simple signature expected by tests)
        audit_log(user_id, "CSV_EXPORT", {"payments": True, "count": len(payments)})
        
        return response

    except Exception as e:
        log.error("CSV export failed: %s", e)
        return _fail(HTTPStatus.INTERNAL_SERVER_ERROR, "EXPORT_FAILED", "CSV export failed")
    finally:
        try:
            conn.close()
        except AttributeError:
            pass

# ----------------------------------------------------------------------------
# Root
# ----------------------------------------------------------------------------
@app.route("/", methods=["GET"])
def root():
    return jsonify(
        {
            "message": "Edgar's Auto Shop S1 API",
            "endpoints": [
                "GET /health",
                "GET /api/admin/appointments/board",
                "GET /api/admin/appointments",
                "POST /api/admin/appointments",
                "PATCH /api/admin/appointments/<id>/status",
                "PATCH /api/admin/appointments/<id>/move",
                "GET /api/appointments/<id>",
                "PATCH /api/appointments/<id>",
                "GET /api/customers/<id>/history",
                "GET /api/admin/dashboard/stats",
                "GET /api/admin/cars-on-premises",
                "GET /api/admin/reports/appointments.csv",
                "GET /api/admin/reports/payments.csv",
            ],
        }
    )


if __name__ == "__main__":
    port = int(os.environ.get("PORT", 3001))
    host = os.environ.get("HOST", "0.0.0.0")
    
    print(f"Starting Edgar's Auto Shop API server on {host}:{port}")
    print(f"Health check: http://localhost:{port}/health")
    print(f"Admin dashboard: http://localhost:5173/admin/dashboard")
    
    app.run(
        host=host,
        port=port,
        debug=True,
        use_reloader=False,  # Disable reloader to prevent double process spawning
        threaded=True
    )
